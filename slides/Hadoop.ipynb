{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8371ee4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a07bb8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 5 W 1 H\n",
    "\n",
    "![](https://jobsgo.vn/blog/wp-content/uploads/2021/05/5w1h-la-gi.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e5d86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is Hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f43a10",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hadoop Web Site\n",
    "\n",
    "![](https://hadoop.apache.org/hadoop-logo.jpg)\n",
    "\n",
    "The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.\n",
    "\n",
    "The Apache Hadoop software library is a framework that allows for the **distributed processing** of **large data sets** across clusters of computers using **simple programming models**. It is designed to **scale up** from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver **high-availability**, the library itself is designed to detect and handle failures **at the application layer**, so delivering a highly-available \n",
    "service on top of a cluster of computers, each of which may be prone to failures.\n",
    "\n",
    "https://hadoop.apache.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d51043",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distributed Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe966123",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It's a generic concept, derives from distribuited systems and involves:\n",
    "- networking\n",
    "- message exchange / protocols\n",
    "- fault tollerance\n",
    "- data distribution\n",
    "- optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbe713",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Architectures:\n",
    "- client-server \n",
    "- 3-tier / n-tier\n",
    "- peer to peer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652da6f5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### In Hadoop \n",
    "distribuited processing means Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbd9453",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Large Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246c6b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://i.imgflip.com/7f12or.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65c71c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simple Programming Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c533b83",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Starting from programming language\n",
    "A programming language is made by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1087e918",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### syntax \n",
    "Set of grammar rules to write correctly the source code, including:\n",
    "- symbols (variables, reserved words)\n",
    "- expressions (constructs)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Syntax_(programming_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b85878",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### execution model\n",
    "specifies the behaviour of the elements, necessary to understand what the code does including:\n",
    "- order of execution\n",
    "- interaction with runtime systems\n",
    "\n",
    "https://en.wikipedia.org/wiki/Execution_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a88565",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### It's like playing a song \n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Lead-sheet-wikipedia.svg/500px-Lead-sheet-wikipedia.svg.png)\n",
    "https://en.wikipedia.org/wiki/Musical_composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5dd113",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a9056",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A Python program is read by a parser. Input to the parser is a stream of tokens, generated by the lexical analyzer. \n",
    "\n",
    "https://docs.python.org/3/reference/lexical_analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622505a",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A Python program is constructed from code blocks. A block is a piece of Python program text that is executed as a unit. The following are blocks: a module, a function body, and a class definition. Each command typed interactively is a block.\n",
    "\n",
    "\n",
    "https://docs.python.org/3/reference/executionmodel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebac4287",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  The Hitchhiker's Guide to Python\n",
    "https://docs.python-guide.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6638b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Finding an example... is not easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202f33f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://i.imgflip.com/7f19b1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed784f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/chatgpt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa93de6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Result\n",
    "Blog post: https://alex.dzyoba.com/blog/python-import/\n",
    "\n",
    "Repository: https://github.com/dzeban/python-imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ceb96",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Zen of Python\n",
    "Beautiful is better than ugly.\n",
    "\n",
    "Explicit is better than implicit.\n",
    "\n",
    "Simple is better than complex.\n",
    "\n",
    "Complex is better than complicated.\n",
    "\n",
    "Flat is better than nested.\n",
    "\n",
    "Sparse is better than dense.\n",
    "\n",
    "Readability counts.\n",
    "\n",
    "Special cases aren't special enough to break the rules.\n",
    "\n",
    "Although practicality beats purity.\n",
    "\n",
    "Errors should never pass silently.\n",
    "\n",
    "Unless explicitly silenced.\n",
    "\n",
    "In the face of ambiguity, refuse the temptation to guess.\n",
    "\n",
    "There should be one-- and preferably only one --obvious way to do it.\n",
    "\n",
    "Although that way may not be obvious at first unless you're Dutch.\n",
    "\n",
    "Now is better than never.\n",
    "\n",
    "Although never is often better than *right* now.\n",
    "\n",
    "If the implementation is hard to explain, it's a bad idea.\n",
    "\n",
    "If the implementation is easy to explain, it may be a good idea.\n",
    "\n",
    "Namespaces are one honking great idea -- let's do more of those!\n",
    "\n",
    "https://mail.python.org/pipermail/python-list/1999-June/001951.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3610d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### To  programming model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e7456",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A programming model is an \n",
    "- execution model \n",
    "- coupled to an API or a particular pattern code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c9256",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So there can be two execution model\n",
    "- the one of the base programming language \n",
    "- the one of the programming model\n",
    "\n",
    "and they can be different!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495da9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Examples\n",
    "| Name     | Base programming language | execution model | \n",
    "| -------| --------------------------|----------------\n",
    "| Spark  | Java,Python,Scala         | Spark           |\n",
    "| Hadoop | Java                      | Map Reduce      |\n",
    "| Thread | C, C++, Java, Python      | POSIX Thread   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142b48d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53db9b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why Does The High Scalability Site Exist?\n",
    "\n",
    "This site tries to bring together all the lore, art, science, practice, and experience of building scalable websites into one place so you can learn how to build your website with confidence.\n",
    "\n",
    "When it becomes clear you must grow your website or die, most people have no idea where to start. It's not a skill you learn in school or pick up from a magazine article on a plane flight home. No, building scalable systems is a body of knowledge slowly built up over time from hard won experience and many failed battles. Hopefully this site will move you further and faster along the learning curve of success.\n",
    "\n",
    "http://highscalability.com/start-here/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9122ea6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### In hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3d718",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Hadoop runs into clusters of nodes\n",
    "\n",
    "Installing a Hadoop cluster typically involves unpacking the software on all the machines in the cluster or installing it via a packaging system as appropriate for your operating system. It is important to divide up the hardware into functions.\n",
    "\n",
    "Typically one machine in the cluster is designated as the NameNode and another machine as the ResourceManager, exclusively. These are the masters. Other services (such as Web App Proxy Server and MapReduce Job History server) are usually run either on dedicated hardware or on shared infrastructure, depending upon the load.\n",
    "\n",
    "The rest of the machines in the cluster act as both DataNode and NodeManager. These are the workers.\n",
    "\n",
    "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html#Web_Interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed5ed6",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://content.linkedin.com/content/dam/engineering/site-assets/images/blog/posts/2021/05/exabyte_club2.png)\n",
    "\n",
    "https://engineering.linkedin.com/blog/2021/scaling-linkedin-s-hadoop-yarn-cluster-beyond-10-000-nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5bb287",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Note\n",
    "Installing from scratch Hadoop is hard !\n",
    "\n",
    "That's why hadoop vendors first and cloud provider later did start package Hadoop \n",
    "\n",
    "Now it's time for Hadoop in Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c33cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### High Avalability at application layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2d86c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "High availability (HA) is a characteristic of a system which aims to ensure an agreed level of operational performance, usually uptime, for a higher than normal period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf5a4c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Principles\n",
    "There are three principles of systems design in reliability engineering which can help achieve high availability.\n",
    "\n",
    "1. Elimination of single points of failure. This means adding or building redundancy into the system so that failure of a component does not mean failure of the entire system.\n",
    "2. Reliable crossover. In redundant systems, the crossover point itself tends to become a single point of failure. Reliable systems must provide for reliable crossover.\n",
    "3. Detection of failures as they occur. If the two principles above are observed, then a user may never see a failure – but the maintenance activity must."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6d9a0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### In hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a819f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### At Storage level\n",
    "\n",
    "**Data Replication**\n",
    "\n",
    "HDFS is designed to reliably store very large files across machines in a large cluster. It stores each file as a sequence of blocks; all blocks in a file except the last block are the same size. The blocks of a file are replicated for fault tolerance. The block size and replication factor are configurable per file. An application can specify the number of replicas of a file. The replication factor can be specified at file creation time and can be changed later. Files in HDFS are write-once and have strictly one writer at any time.\n",
    "\n",
    "The NameNode makes all decisions regarding replication of blocks. It periodically receives a Heartbeat and a Blockreport from each of the DataNodes in the cluster. Receipt of a Heartbeat implies that the DataNode is functioning properly. A Blockreport contains a list of all blocks on a DataNode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4630a70",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### At computing level\n",
    "\n",
    "**Application Master** \n",
    "\n",
    "When the application master is notified of a task attempt that has failed, it will reschedule execution of the task. The application master will try to avoid rescheduling the task on a node manager where it has previously failed. Furthermore, if a task fails four times, it will not be retried again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22b874",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Hadoop Components "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2267b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b000d",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hadoop Common**\n",
    "\n",
    "The common utilities that support the other Hadoop modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b0d1e",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hadoop YARN**\n",
    "\n",
    "A framework for job scheduling and cluster resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701414",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hadoop Distributed File System (HDFS™)**\n",
    "\n",
    "A distributed file system that provides high-throughput access to application data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377a0df",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hadoop MapReduce** \n",
    "\n",
    "A YARN-based system for parallel processing of large data sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330ed67",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Related Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0822a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Ambari™: A web-based tool for provisioning, managing, and monitoring Apache Hadoop clusters which includes support for Hadoop HDFS, Hadoop MapReduce, Hive, HCatalog, HBase, ZooKeeper, Oozie, Pig and Sqoop. Ambari also provides a dashboard for viewing cluster health such as heatmaps and ability to view MapReduce, Pig and Hive applications visually alongwith features to diagnose their performance characteristics in a user-friendly manner.\n",
    "- Avro™: A data serialization system.\n",
    "- Cassandra™: A scalable multi-master database with no single points of failure.\n",
    "- Chukwa™: A data collection system for managing large distributed systems.\n",
    "- HBase™: A scalable, distributed database that supports structured data storage for large tables.\n",
    "- Hive™: A data warehouse infrastructure that provides data summarization and ad hoc querying.\n",
    "- Mahout™: A Scalable machine learning and data mining library.\n",
    "- Ozone™: A scalable, redundant, and distributed object store for Hadoop.\n",
    "- Pig™: A high-level data-flow language and execution framework for parallel computation.\n",
    "- Spark™: A fast and general compute engine for Hadoop data. Spark provides a simple and expressive programming model that supports a wide range of applications, including ETL, machine learning, stream processing, and graph computation.\n",
    "- Submarine: A unified AI platform which allows engineers and data scientists to run Machine Learning and Deep Learning workload in distributed cluster.\n",
    "- Tez™: A generalized data-flow programming framework, built on Hadoop YARN, which provides a powerful and flexible engine to execute an arbitrary DAG of tasks to process data for both batch and interactive use-cases. Tez is being adopted by Hive™, Pig™ and other frameworks in the Hadoop ecosystem, and also by other commercial software (e.g. ETL tools), to replace Hadoop™ MapReduce as the underlying execution engine.\n",
    "- ZooKeeper™: A high-performance coordination service for distributed applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfa59e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hadoop ecosystem table (retired)\n",
    "https://hadoopecosystemtable.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8fb263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Hadoop is important ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa731d7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hadoop is important because it allows for the processing of large and complex data sets that cannot be processed by traditional computing methods. It enables organizations to efficiently store and process massive amounts of data, making it possible to extract valuable insights and make informed decisions.\n",
    "\n",
    "ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4dd277",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Save Money"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28055180",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">Hadoop was created by Doug Cutting, the creator of Apache Lucene, the widely used text search library. Hadoop has its origins in Apache Nutch, an open source web search engine, itself a part of the Lucene project.\n",
    "...\n",
    "Building a web search engine from scratch was an ambitious goal, ...\n",
    "It’s expensive, too: Mike Cafarella and Doug Cutting estimated a system supporting a onebillion-page index would cost around 500,000 in hardware, with a monthly running cost of 30,000.\n",
    "\n",
    "A Brief History of Apache Hadoop, Hadoop the Definitive Guide, Tom White"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b093c59",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## To be able to compute big data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538c06b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "According to an article published by IBM, traditional computing systems are designed to handle data sets that can fit into a single machine's memory. As the size of the data set grows beyond the capacity of a single machine, traditional systems become inefficient, slow, and expensive. In contrast, Hadoop is designed to handle data sets that are too large to fit into a single machine's memory by distributing the data and processing across a cluster of machines. This approach allows for parallel processing of large data sets, making Hadoop faster and more efficient than traditional systems for large-scale data processing. Additionally, Hadoop's fault-tolerant architecture enables it to recover from hardware failures, which is essential for large data sets that may span multiple machines.\n",
    "\n",
    "IBM. \"What is Hadoop?\". IBM.com. https://www.ibm.com/cloud/learn/hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d271d11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Who needs to use hadoop ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b82f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hadoop can be useful for a wide range of organizations and industries that work with large amounts of data. Here are a few examples of who might benefit from using Hadoop:\n",
    "\n",
    "- E-commerce companies that need to process large volumes of customer data to gain insights into purchasing patterns, product recommendations, and customer behavior.\n",
    "- Healthcare organizations that need to analyze patient data for medical research, disease diagnosis, and treatment.\n",
    "- Financial institutions that need to analyze large amounts of transaction data to detect fraud and identify trends in financial markets.\n",
    "- Government agencies that need to process large amounts of data for public safety, security, and policy-making purposes.\n",
    "- Social media companies that need to process large amounts of user-generated data for personalized recommendations, targeted advertising, and trend analysis.\n",
    "\n",
    "In general, any organization that needs to process and analyze large volumes of data can benefit from using Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ebff2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Also in 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb559a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hadoop is still a valid technology in 2023. While there are other big data technologies that have emerged in recent years, such as Apache Spark and Apache Flink, Hadoop remains a popular and widely used platform for distributed computing and big data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9882a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hadoop has a large and active community of users and developers who continue to improve and maintain the platform. In addition, many companies have invested heavily in Hadoop infrastructure and continue to use it as a core component of their big data processing pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3f5f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, it's worth noting that Hadoop has also evolved over time to incorporate newer technologies and approaches, such as the integration of Spark as a processing engine and the use of cloud-based Hadoop offerings. As such, it's important to stay up-to-date with the latest developments in the Hadoop ecosystem to ensure that you are making the most of this powerful technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56013264",
   "metadata": {},
   "source": [
    "![](https://www.maximizemarketresearch.com/wp-content/uploads/2019/11/Global-Hadoop-Big-Data-Analytics-Market-1.png)\n",
    "https://www.maximizemarketresearch.com/market-report/global-hadoop-big-data-analytics-market/6866/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a4a6c",
   "metadata": {},
   "source": [
    "# How it works ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6a0dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023cdfe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*icizuNuhN_1VFIT1_voWsw.jpeg)\n",
    "https://towardsdatascience.com/series-on-distributed-computing-1-mapreduce-fcc3cc2dfb5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59cf63",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d4c53",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png)\n",
    "https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c74166",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where to use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23b230",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://i.imgflip.com/7f1pf6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75557fa2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41b910",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Amazon EMR**\n",
    "\n",
    "Easily run and scale Apache Spark, Hive, Presto, and other big data workloads\n",
    "\n",
    "https://aws.amazon.com/emr/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b8134",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://d1.awsstatic.com/products/EMR/Product-Page-Diagram_Amazon-EMR.803d6adad956ba21ceb96311d15e5022c2b6722b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add1695",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2323e2",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**HD Insight**\n",
    "\n",
    "Run popular open-source frameworks—including Apache Hadoop, Spark, Hive, Kafka, and more—using Azure HDInsight, a customizable, enterprise-grade service for open-source analytics. Effortlessly process massive amounts of data and get all the benefits of the broad open-source project ecosystem with the global scale of Azure. Easily migrate your big data workloads and processing to the cloud.\n",
    "\n",
    "https://azure.microsoft.com/en-gb/products/hdinsight/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db9587",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/hdinsight_integrate?resMode=sharp2&op_usm=1.5,0.65,15,0&wid=2908&hei=1724&qlt=100&fmt=png-alpha&fit=constrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff0093",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Google Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77beb7",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Dataproc**\n",
    "\n",
    "Dataproc is a fully managed and highly scalable service for running Apache Hadoop, Apache Spark, Apache Flink, Presto, and 30+ open source tools and frameworks. Use Dataproc for data lake modernization, ETL, and secure data science, at scale, integrated with Google Cloud, at a fraction of the cost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b83fa5",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://4.bp.blogspot.com/-iIEZ8nIeFTk/Vh16SPiU9KI/AAAAAAAABdI/Fr9zYhYqQkI/s640/Dataproc.png)\n",
    "\n",
    "[Launch](https://cloudplatform.googleblog.com/2015/09/Google-Cloud-Dataproc-Making-Spark-and-Hadoop-Easier-Faster-and-Cheaper.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952bae5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time do practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5ac12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Word Count with Map Reduce on DataProc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b03483",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://miro.com/app/board/uXjVMcdLcug=/?share_link_id=121090137939"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cab25c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tutorials\n",
    "- https://www.cloudskillsboost.google/focuses/672?catalog_rank=%7B%22rank%22%3A9%2C%22num_filters%22%3A0%2C%22has_search%22%3Atrue%7D&parent=catalog&search_id=22899007\n",
    "- https://cloud.google.com/composer/docs/tutorials/hadoop-wordcount-job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af98c16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d40b37",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- https://hadoop.apache.org/\n",
    "- https://www.linkedin.com/learning/learning-hadoop-2/getting-started-with-hadoop?autoplay=true\n",
    "- https://www.projectpro.io/article/hadoop-vs-spark-not-mutually-exclusive-but-better-together/235\n",
    "- https://towardsdatascience.com/series-on-distributed-computing-1-mapreduce-fcc3cc2dfb5\n",
    "- https://www.databricks.com/glossary/hadoop-ecosystem\n",
    "- https://medium.com/geekculture/mapreduce-with-python-5d12a772d5b3\n",
    "- https://engineering.linkedin.com/blog/2021/scaling-linkedin-s-hadoop-yarn-cluster-beyond-10-000-nodes\n",
    "- https://www.uber.com/en-IT/blog/scaling-hdfs/\n",
    "- https://engineering.linkedin.com/blog/2021/the-exabyte-club--linkedin-s-journey-of-scaling-the-hadoop-distr\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": "true",
   "footer": "<div class=\"tswd-footer\"> *** Cloud Computing and Big Data - 2023 ***</div>",
   "header": "<div class=\"tswd-header\"></div>",
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
